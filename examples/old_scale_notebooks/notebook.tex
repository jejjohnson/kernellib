
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{asvd\_tutorial}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{approximate-singular-value-decomposition}{%
\section{Approximate Singular Value
Decomposition}\label{approximate-singular-value-decomposition}}

    \hypertarget{synopsis}{%
\subsubsection{Synopsis}\label{synopsis}}

    I use the eigenvalue decomposition method whenever I implement any
Manifold Learning method. The general steps one must take in order to
implement these methods would be:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Construct a Connectivity Matrix
\item
  Solve the Eigenvalue Decomposition Problem
\item
  Extract the k-smallest nontrivial eigenvalues and the corresponding
  eigenvectors to either extract the embedding or project the data into
  the new space where the embedding is present.
\end{enumerate}

Now, step 2 is very computationally heavy so I am looking for methods
which can reduce the computaitonal burden. From my understanding, the
Approximate Singular Value Decomposition (ASVD) method uses the theory
of random approximations of spectral decompositions to find the best
rank-k approximation of a matrix A. This sounds particularly useful
because it will speed up the entire algorithm process and it is a method
that has some pretty good theoretical guarantees to ensure that we have
a good solution.

    \hypertarget{resources}{%
\subsubsection{Resources}\label{resources}}

    I will be using the following papers to complete my self tutorial:

\hypertarget{theory}{%
\section{Theory}\label{theory}}

\begin{itemize}
\tightlist
\item
  Randomized Approximate of Operators and their Spectral Decomposition
  for Diffusion Based Embeddings of Hetergeneous Data

  \begin{itemize}
  \tightlist
  \item
    Czaja et al. -
    \href{http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7330267\&tag=1}{Paper}
  \end{itemize}
\item
  A randomized algorithm for principal component analysis

  \begin{itemize}
  \tightlist
  \item
    Rokhlin et al. - \href{http://arxiv.org/pdf/0809.2274.pdf}{Paper}
  \end{itemize}
\item
  Finding Structure with Randomness: Probabilistic Algorithms for
  Constructing Approximate Matrix Decompositions

  \begin{itemize}
  \tightlist
  \item
    Halko et al. - \href{https://arxiv.org/pdf/0909.4061}{Paper}
  \end{itemize}
\item
  A randomized algorithm for the decomposition of matrices

  \begin{itemize}
  \tightlist
  \item
    Martisson et al. -
    \href{https://math.berkeley.edu/~strain/273.F10/martinsson.tygert.rokhlin.randomized.decomposition.pdf}{Paper}
  \end{itemize}
\end{itemize}

\hypertarget{practical}{%
\section{Practical}\label{practical}}

\begin{itemize}
\tightlist
\item
  A Practical Guide to Randomized Algorithms in MATLAB

  \begin{itemize}
  \tightlist
  \item
    \href{https://arxiv.org/pdf/1505.07570.pdf}{Paper} \textbar{}
    \href{https://github.com/wangshusen/RandMatrixMatlab}{Code}
  \end{itemize}
\item
  Course: Fast AI - Randomized SVD

  \begin{itemize}
  \tightlist
  \item
    \href{https://github.com/fastai/randomized-SVD}{github}
  \end{itemize}
\end{itemize}

\hypertarget{source-codes}{%
\section{Source Codes}\label{source-codes}}

I will use the following code as a guide for implementing the steps in
the paper:

\begin{itemize}
\tightlist
\item
  Github user - \href{https://gist.github.com/alextp/662433}{gist}
\item
  Github user - \href{https://github.com/ktaneishi/pyredsvd}{github}
\item
  Facebook: Fast Randomized PCA/SVD -
  \href{https://github.com/facebook/fbpca/blob/master/fbpca.py}{github}
\item
  Scikit-Learn: Randomized SVD -
  \href{https://github.com/scikit-learn/scikit-learn/blob/51a765acfa4c5d1ec05fc4b406968ad233c75162/sklearn/utils/extmath.py}{github}
\item
  Mu Li: Randomized SVD -
  \href{https://github.com/mli/nystrom/blob/master/rsvd.m}{github}
\end{itemize}

    \hypertarget{algorithm-walkthrough}{%
\subsection{Algorithm Walkthrough}\label{algorithm-walkthrough}}

    Suppose we have a real matrix A of size \(m\times n\). This can be
typically decomposed via regular SVD as

\[A=U\Sigma V^T\]

where: * \(U\) is a real unitary \(m\times m\) matrix * \(V\) is a real
unitary \(n \times n\) matrix * \(\Sigma\) is a real \(m\times n\)
diagonal matrix

A well known idea is that the best rank-\(k\) approximation of A is
given by

\[A=\tilde{U}\tilde{\Sigma}\tilde{V}^T\]

where: * \(\tilde{U}\) is a real unitary \(m\times k\) matrix *
\(\tilde{V}\) is a real unitary \(n \times k\) matrix *
\(\tilde{\Sigma}\) is a real \(k\times k\) diagonal matrix We now want
to form a Gaussian matrix

    \hypertarget{step-1---gaussian-matrix}{%
\subsubsection{Step 1 - Gaussian
Matrix}\label{step-1---gaussian-matrix}}

    Let \(A\) be a real \(m\times n\) matrix.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{} get some random matrix}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{import} \PY{n}{make\PYZus{}spd\PYZus{}matrix}
        
        \PY{n}{A} \PY{o}{=} \PY{n}{make\PYZus{}spd\PYZus{}matrix}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
        
        \PY{n}{m} \PY{o}{=} \PY{n}{A}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}  \PY{c+c1}{\PYZsh{} left dimension of A}
        \PY{n}{n} \PY{o}{=} \PY{n}{A}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}  \PY{c+c1}{\PYZsh{} right dimension of A}
        
        \PY{c+c1}{\PYZsh{} choose some k singular values we want}
        \PY{n}{k} \PY{o}{=} \PY{l+m+mi}{10}
\end{Verbatim}


    Construct a matrix, \(G\), of i.i.d. standard Gaussian random variables,
s.t. the matrix is size \(l\times m\) where \(k<l\leq m-k\).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{} choose some l that satisfies the inequality listed above}
        \PY{n}{l} \PY{o}{=} \PY{l+m+mi}{20}
        
        \PY{c+c1}{\PYZsh{} assert that the inequality is satisfied}
        \PY{k}{def} \PY{n+nf}{check\PYZus{}l}\PY{p}{(}\PY{n}{l}\PY{p}{)}\PY{p}{:}
            \PY{k}{assert} \PY{n}{l} \PY{o}{\PYZgt{}} \PY{n}{k} \PY{o+ow}{and} \PY{n}{l} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{p}{(}\PY{n}{m}\PY{o}{\PYZhy{}}\PY{n}{k}\PY{p}{)}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Your choice of l must satisfy the inequality.}\PY{l+s+s2}{\PYZdq{}}
            \PY{k}{return} \PY{n}{l}
        
        \PY{c+c1}{\PYZsh{} check my value of l}
        \PY{n}{l} \PY{o}{=} \PY{n}{check\PYZus{}l}\PY{p}{(}\PY{n}{l}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} create gaussian matrix}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        
        \PY{n}{G} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{l}\PY{p}{,}\PY{n}{m}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \hypertarget{step-2---compute-product}{%
\subsubsection{Step 2 - Compute
Product}\label{step-2---compute-product}}

    Compute the product of the following:

\[S=G(AA^T)^iA\]

where \(i \in \mathbb{N}\). To get an idea of the dimensions, it is:

\[S=G_{l\times m}(A_{m \times n}A_{n \times m}^T)^iA_{m \times n}\]

This is actually a pretty involved product so I'm going to break down
the steps even further.

    \hypertarget{compute-the-square-matrix}{%
\subparagraph{Compute the square
matrix}\label{compute-the-square-matrix}}

It would seem that the product \(AA^T\) is only need because \(A\) is an
\(m \times n\) matrix. This would not be needed if \(A=A^T\), i.e.~a
symmetric matrix. In fact, it might be the case that doing \(AA^T\) for
a symmetric matrix would count as doing an extra iteration for the next
step.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{} compute the square matrix}
        \PY{n}{A\PYZus{}square} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{A}\PY{p}{,} \PY{n}{A}\PY{o}{.}\PY{n}{T}\PY{p}{)}
\end{Verbatim}


    \hypertarget{compute-the-power-of-the-square-matrix}{%
\subparagraph{Compute the Power of the square
matrix}\label{compute-the-power-of-the-square-matrix}}

This involves the \((AA^T)^{i}\). I'm pretty sure that
\(i \in \mathbb{N}\) and by increasing \(i\) increases the accuracy of
the method.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} compute the matrix power}
        \PY{n}{i} \PY{o}{=} \PY{l+m+mi}{2}
        \PY{n}{A\PYZus{}power} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{matrix\PYZus{}power}\PY{p}{(}\PY{n}{A\PYZus{}square}\PY{p}{,}\PY{n}{i}\PY{p}{)}
\end{Verbatim}


    \hypertarget{now-compute-the-actual-product}{%
\subparagraph{Now Compute the actual
product}\label{now-compute-the-actual-product}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} compute the product for step 2}
        \PY{n}{S} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{G}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{A\PYZus{}square}\PY{p}{,}\PY{n}{A}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \hypertarget{step-3.-compute-the-pivoted-qr-decomposition}{%
\subsubsection{Step 3. Compute the Pivoted
QR-Decomposition}\label{step-3.-compute-the-pivoted-qr-decomposition}}

    So, we need to use a pivoted \(QR\)-decomposition on the \(S^T\) matrix
computed in step 2 so that we get

\[S^T=QR\]

where \(Q\) is an \(n \times l\) matrix with orthonormal columns.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{c+c1}{\PYZsh{} compute the QR\PYZhy{}decomposition on S transpose}
        \PY{n}{Q}\PY{p}{,} \PY{n}{R} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{qr}\PY{p}{(}\PY{n}{S}\PY{o}{.}\PY{n}{T}\PY{p}{,}\PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{complete}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    There are so many options for the QR decomposition in the numpy package.
The `reduced' mode returns with reduced dimensions so I decided to use
the `complete' mode just in case it cuts some stuff out that we need for
later. I could do some experiments later because I suspect that the
reduced method may be a little bit faster.

\textbf{Note:} Not sure if they have a sparse package in the scipy
library. May have to figure out another way to do it.

    \hypertarget{step-4.-compute-the-svd-of-taq}{%
\subsubsection{\texorpdfstring{Step 4. Compute the SVD of
\(T:=AQ\)}{Step 4. Compute the SVD of T:=AQ}}\label{step-4.-compute-the-svd-of-taq}}

    Now we compute the following SVD

\[T=\tilde{U}\tilde{\Sigma}W^T\]

If we let \(T:=AQ\), we get a much faster SVD computation than just
performing SVD on \(A\) alone because \(T\) is size \(m \times l\).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{T} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{A}\PY{p}{,}\PY{n}{Q}\PY{p}{)}
        \PY{n}{U\PYZus{}hat}\PY{p}{,} \PY{n}{Sigma\PYZus{}hat}\PY{p}{,} \PY{n}{W} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{svd}\PY{p}{(}\PY{n}{T}\PY{p}{)}
\end{Verbatim}


    \hypertarget{step-5.-compute-tildev}{%
\subsubsection{\texorpdfstring{Step 5. Compute
\(\tilde{V}\)}{Step 5. Compute \textbackslash{}tilde\{V\}}}\label{step-5.-compute-tildev}}

    This is done by the following assignment:

\[\tilde{V}:=QW\]

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{n}{V\PYZus{}hat} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{Q}\PY{p}{,}\PY{n}{W}\PY{p}{)}
\end{Verbatim}


    \hypertarget{step-6.-extract-u-sigma-and-v}{%
\subsubsection{\texorpdfstring{Step 6. Extract \(U\), \(\Sigma\), and
\(V\)}{Step 6. Extract U, \textbackslash{}Sigma, and V}}\label{step-6.-extract-u-sigma-and-v}}

    Now we can extract the necessary SVD from our algorithm.

\begin{itemize}
\tightlist
\item
  Extract upper left \(m\times k\) block from \(\tilde{U}\)
\item
  Extract upper left \(n\times k\) block from \(\tilde{V}\)
\item
  Extract upper left \(k\times k\) block from \(\tilde{\Sigma}\)
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{n}{U} \PY{o}{=} \PY{n}{U\PYZus{}hat}\PY{p}{[}\PY{p}{:}\PY{n}{m}\PY{p}{,} \PY{p}{:}\PY{n}{k}\PY{p}{]}
        \PY{n}{V} \PY{o}{=} \PY{n}{V\PYZus{}hat}\PY{p}{[}\PY{p}{:}\PY{n}{n}\PY{p}{,} \PY{p}{:}\PY{n}{k}\PY{p}{]}
        \PY{n}{Sigma} \PY{o}{=} \PY{n}{Sigma\PYZus{}hat}\PY{p}{[}\PY{p}{:}\PY{n}{k}\PY{p}{]}
\end{Verbatim}


    \hypertarget{asvd-function}{%
\subsection{ASVD Function}\label{asvd-function}}

    To get away from the imperative style tutorial above, I'm defining a
function that contains all of the elements that I outlined above.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{k}{def} \PY{n+nf}{asvd}\PY{p}{(}\PY{n}{A}\PY{p}{,} \PY{n}{n\PYZus{}components}\PY{p}{,} \PY{n}{size\PYZus{}gauss}\PY{p}{,} \PY{n}{pow\PYZus{}iter}\PY{p}{)}\PY{p}{:}
             
             \PY{c+c1}{\PYZsh{} get components}
             \PY{n}{m} \PY{o}{=} \PY{n}{A}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{;} \PY{n}{n} \PY{o}{=} \PY{n}{A}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
             \PY{n}{k} \PY{o}{=} \PY{n}{n\PYZus{}components}
             \PY{n}{l} \PY{o}{=} \PY{n}{size\PYZus{}gauss}
             \PY{n}{i} \PY{o}{=} \PY{n}{pow\PYZus{}iter}
             \PY{k}{assert} \PY{n}{l} \PY{o}{\PYZgt{}} \PY{n}{k} \PY{o+ow}{and} \PY{n}{l} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{p}{(}\PY{n}{m}\PY{o}{\PYZhy{}}\PY{n}{k}\PY{p}{)}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Your choice of l must satisfy the inequality.}\PY{l+s+s2}{\PYZdq{}}
             
             \PY{c+c1}{\PYZsh{} perform ASVD}
             \PY{n}{G} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{l}\PY{p}{,}\PY{n}{m}\PY{p}{)}\PY{p}{)}
             \PY{n}{A\PYZus{}square} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{A}\PY{p}{,} \PY{n}{A}\PY{o}{.}\PY{n}{T}\PY{p}{)}
             \PY{n}{A\PYZus{}power} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{matrix\PYZus{}power}\PY{p}{(}\PY{n}{A\PYZus{}square}\PY{p}{,}\PY{n}{i}\PY{p}{)}
             \PY{n}{S} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{G}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{A\PYZus{}square}\PY{p}{,}\PY{n}{A}\PY{p}{)}\PY{p}{)}
             \PY{n}{Q}\PY{p}{,} \PY{n}{R} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{qr}\PY{p}{(}\PY{n}{S}\PY{o}{.}\PY{n}{T}\PY{p}{,}\PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{complete}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{T} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{A}\PY{p}{,}\PY{n}{Q}\PY{p}{)}
             \PY{n}{U\PYZus{}hat}\PY{p}{,} \PY{n}{Sigma\PYZus{}hat}\PY{p}{,} \PY{n}{W} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{svd}\PY{p}{(}\PY{n}{T}\PY{p}{)}
             \PY{n}{V\PYZus{}hat} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{Q}\PY{p}{,}\PY{n}{W}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} extract n\PYZus{}components}
             \PY{n}{U} \PY{o}{=} \PY{n}{U\PYZus{}hat}\PY{p}{[}\PY{p}{:}\PY{n}{m}\PY{p}{,} \PY{p}{:}\PY{n}{k}\PY{p}{]}
             \PY{n}{V} \PY{o}{=} \PY{n}{V\PYZus{}hat}\PY{p}{[}\PY{p}{:}\PY{n}{n}\PY{p}{,} \PY{p}{:}\PY{n}{k}\PY{p}{]}
             \PY{n}{Sigma} \PY{o}{=} \PY{n}{Sigma\PYZus{}hat}\PY{p}{[}\PY{p}{:}\PY{n}{k}\PY{p}{]}
             
             \PY{k}{return} \PY{n}{U}\PY{p}{,} \PY{n}{Sigma}\PY{p}{,} \PY{n}{V}
\end{Verbatim}


    \hypertarget{more-compact-asvd-function}{%
\subsection{More Compact ASVD
Function}\label{more-compact-asvd-function}}

    The next step is to reduce the memory used for this function. I don't
need to be implementing all these assignments when I can keep those
contained within functions; really one of the highlights of python.

    \hypertarget{smallest-eigenvalues-and-eigenvectors}{%
\subsection{Smallest Eigenvalues and
Eigenvectors}\label{smallest-eigenvalues-and-eigenvectors}}

    So the above method computes the largest eigenvalues of the given
matrix. In order to compute the smallest eigenvalues, we have to do a
trick:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Let \(k=1\).
\item
  Use ASVD to compute the largest \(k\) eigenvalues of the matrix, i.e.
  \(\sigma_1\).
\item
  Transform A like so:
  \(\mathbf{A}' = 2\sigma_1 \mathbf{I}-\mathbf{A}\).
\item
  Use ASVD to solve for the largest \(k\)' eigenvalues and eigenvectors
  of the matrix, \(\mathbf{A}'\).
\item
  The smallest eigenvalues and eigenvectors are given by:
  \(\Sigma=2\sigma_1 \mathbf{I}-\Sigma'\)
\end{enumerate}

\textbf{Note}: We can actually keep the same eigenvectors as the
\(\mathbf{A}'\) matrix for the smallest eigenvalues.

Let's have the following eigenvalue formula:

\begin{equation}
\mathbf{A}\vec{x}=\lambda\vec{x}
\end{equation}

Now let's add some arbitrary scaling parameter \(\gamma \mathbf{I}\) to
the \(\mathbf{A}\). Using the above equation, we can deduce that:

\begin{align}
\left(\gamma \mathbf{I+A}\right)\vec{x} &= \gamma \mathbf{I} \vec{x} + \mathbf{A}\vec{x} \\
    &= \gamma \vec{x} + \lambda \vec{x}\\
    &= \left( \gamma + \lambda \right) \vec{x}
\end{align}

Therefore, \(\gamma + \lambda\) is an eigenvalue but \(\vec{x}\) is
still the same eigenvector.

    \hypertarget{example}{%
\subparagraph{Example}\label{example}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{} set parameters}
         \PY{n}{n\PYZus{}components} \PY{o}{=} \PY{l+m+mi}{5}  \PY{c+c1}{\PYZsh{} i\PYZsq{}m looking for the 5 smallest and largest eigenvectors for the same matrix A}
         \PY{n}{size\PYZus{}gauss} \PY{o}{=} \PY{l+m+mi}{30}
         \PY{n}{pow\PYZus{}iter} \PY{o}{=} \PY{l+m+mi}{20}
         
         \PY{c+c1}{\PYZsh{} solve for the largest eigenvalue}
         \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{Sigma\PYZus{}large}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{asvd}\PY{p}{(}\PY{n}{A}\PY{p}{,} \PY{n}{n\PYZus{}components}\PY{o}{=}\PY{n}{n\PYZus{}components}\PY{p}{,}
                            \PY{n}{size\PYZus{}gauss}\PY{o}{=}\PY{n}{size\PYZus{}gauss}\PY{p}{,} 
                            \PY{n}{pow\PYZus{}iter}\PY{o}{=}\PY{n}{pow\PYZus{}iter}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} transform the original matrix A to A\PYZsq{}}
         \PY{n}{A\PYZus{}new} \PY{o}{=} \PY{l+m+mi}{2}\PY{o}{*}\PY{n}{Sigma\PYZus{}large}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{eye}\PY{p}{(}\PY{n}{A}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{A}
         
         \PY{c+c1}{\PYZsh{} solve for the largest k components of the matrix A\PYZsq{}}
         \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{Sigma}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{asvd}\PY{p}{(}\PY{n}{A\PYZus{}new}\PY{p}{,} \PY{n}{n\PYZus{}components}\PY{o}{=}\PY{n}{n\PYZus{}components}\PY{p}{,}
                            \PY{n}{size\PYZus{}gauss}\PY{o}{=}\PY{n}{size\PYZus{}gauss}\PY{p}{,}
                            \PY{n}{pow\PYZus{}iter}\PY{o}{=}\PY{n}{pow\PYZus{}iter}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} use transformation to find the smallest eigenvalues}
         \PY{n}{Sigma\PYZus{}small} \PY{o}{=} \PY{l+m+mi}{2}\PY{o}{*}\PY{n}{Sigma\PYZus{}large}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{\PYZhy{}}\PY{n}{Sigma}
         
         \PY{c+c1}{\PYZsh{} find all of the eigenvalues}
         \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{Sigma}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{svd}\PY{p}{(}\PY{n}{A}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} just check to see if the results are the same}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The largest }\PY{l+s+si}{\PYZob{}k\PYZcb{}}\PY{l+s+s1}{ eigenvalues for A:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+si}{\PYZob{}eig\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{n}{n\PYZus{}components}\PY{p}{,}\PY{n}{eig}\PY{o}{=}\PY{n}{Sigma\PYZus{}large}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Using the SVD function:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+si}{\PYZob{}eig\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{eig}\PY{o}{=}\PY{n}{Sigma}\PY{p}{[}\PY{p}{:}\PY{n}{n\PYZus{}components}\PY{p}{]}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The same? }\PY{l+s+si}{\PYZob{}ans\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{ans}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n}{Sigma\PYZus{}large} \PY{o}{\PYZhy{}} \PY{n}{Sigma}\PY{p}{[}\PY{p}{:}\PY{n}{n\PYZus{}components}\PY{p}{]}\PY{p}{)}\PY{o}{\PYZlt{}}\PY{l+m+mf}{1E\PYZhy{}10}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The smallest }\PY{l+s+si}{\PYZob{}k\PYZcb{}}\PY{l+s+s1}{ eigenvalues for A:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+si}{\PYZob{}eig\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{n}{n\PYZus{}components}\PY{p}{,}\PY{n}{eig}\PY{o}{=}\PY{n}{Sigma\PYZus{}small}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Using the SVD function:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+si}{\PYZob{}eig\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{eig}\PY{o}{=}\PY{n}{Sigma}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{n}{n\PYZus{}components}\PY{p}{]}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The same? }\PY{l+s+si}{\PYZob{}ans\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{ans}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n}{Sigma\PYZus{}small} \PY{o}{\PYZhy{}} \PY{n}{Sigma}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{n}{n\PYZus{}components}\PY{p}{]}\PY{p}{)}\PY{o}{\PYZlt{}}\PY{l+m+mf}{1E\PYZhy{}10}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The largest 5 eigenvalues for A:
[100.49708086   0.99603269   0.99283061   0.98404493   0.97890796]
Using the SVD function:
[100.49708086   0.99603269   0.99283061   0.98404493   0.97890796]
The same? True
The smallest 5 eigenvalues for A:
[0.00258032 0.00694713 0.01430953 0.02844083 0.03210657]
Using the SVD function:
[0.00258032 0.00694713 0.01430953 0.02844083 0.03210657]
The same? True

    \end{Verbatim}

    \hypertarget{where-are-the-eigenvectors-in-an-svd}{%
\paragraph{Where are the eigenvectors in an
SVD?}\label{where-are-the-eigenvectors-in-an-svd}}

    I'll just do an experiment where I compute the solution to the
generalized eigenvalue problem using SVD and some other method.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{linalg} \PY{k}{import} \PY{n}{eig}
         \PY{n}{U}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}\PY{p}{;} \PY{n}{Sigma}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}\PY{p}{;} \PY{n}{V}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{n}{U}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{svd}\PY{p}{(}\PY{n}{A}\PY{p}{)}
         \PY{n}{U}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{asvd}\PY{p}{(}\PY{n}{A}\PY{p}{,} \PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,}
                                                    \PY{n}{size\PYZus{}gauss}\PY{o}{=}\PY{n}{size\PYZus{}gauss}\PY{p}{,}
                                                    \PY{n}{pow\PYZus{}iter}\PY{o}{=}\PY{n}{pow\PYZus{}iter}\PY{p}{)}
         \PY{n}{eigVals} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}\PY{p}{;} \PY{n}{eigVecs} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{n}{eigVals}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{eigVecs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{eig}\PY{p}{(}\PY{n}{a}\PY{o}{=}\PY{n}{A}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{eigVecs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{,} \PY{p}{:}\PY{n}{n\PYZus{}components}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{,} \PY{p}{:}\PY{n}{n\PYZus{}components}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{eigVecs}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{,} \PY{p}{:}\PY{n}{n\PYZus{}components}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{eigVals}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(100, 100) (100, 10) (100, 100)
[[-0.05956788 -0.08791196 -0.17417145 -0.04740637  0.00759859]
 [-0.00759328 -0.23749074 -0.05009837 -0.08681157 -0.08235621]
 [ 0.11349362  0.0180285  -0.10913929 -0.17421939 -0.07026755]
 [-0.1997493   0.01389396  0.0518404   0.07702102 -0.17090324]
 [ 0.00489798  0.00536418  0.1232994   0.10461716 -0.19734486]]
[[-0.05956816 -0.02390722 -0.01488936  0.00110954 -0.09957276]
 [-0.08791237  0.15275019  0.01413528  0.090926    0.0253037 ]
 [-0.17417163 -0.06456656  0.03903458 -0.1787586  -0.16937355]
 [-0.04740536  0.0512126  -0.05033844  0.16663881 -0.08854143]
 [ 0.00759908  0.05495391  0.05079448  0.0236086   0.1239081 ]]
[[ 0.05956788 -0.00759328  0.11349362 -0.1997493  -0.00489798]
 [ 0.08791196 -0.23749074  0.0180285   0.01389396 -0.00536418]
 [ 0.17417145 -0.05009837 -0.10913929  0.0518404  -0.1232994 ]
 [ 0.04740637 -0.08681157 -0.17421939  0.07702102 -0.10461716]
 [-0.00759859 -0.08235621 -0.07026755 -0.17090324  0.19734486]]




[100.49708086   0.99603269   0.99283061   0.98404493   0.97890796]
[100.49708086   0.99603269   0.99283061   0.98404493   0.97890796]
[100.49708086+0.j   0.99603269+0.j   0.99283061+0.j   0.98404493+0.j
   0.97890796+0.j]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{c+c1}{\PYZsh{} plot the two solutions and compare the values}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
         \PY{n}{plt}\PY{o}{.}\PY{n}{style}\PY{o}{.}\PY{n}{use}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ggplot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SVD}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ASVD}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{eigVals}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Generalized Eigenvalue Problem}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{First }\PY{l+s+si}{\PYZob{}k\PYZcb{}}\PY{l+s+s1}{ Eigenvalues of Matrix A}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{n}{k}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZdl{}}\PY{l+s+s1}{\PYZbs{}}\PY{l+s+s1}{lambda\PYZus{}i\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number \PYZdl{}i\PYZdl{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper right}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
/Users/eman/anaconda3/envs/kernellib/lib/python3.6/site-packages/numpy/core/numeric.py:501: ComplexWarning: Casting complex values to real discards the imaginary part
  return array(a, dtype, copy=False, order=order)

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_45_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{comparing-implementations}{%
\subsection{Comparing Implementations}\label{comparing-implementations}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} get some random matrix}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{import} \PY{n}{make\PYZus{}spd\PYZus{}matrix}
         
         \PY{n}{A} \PY{o}{=} \PY{n}{make\PYZus{}spd\PYZus{}matrix}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         
         \PY{n}{m} \PY{o}{=} \PY{n}{A}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}  \PY{c+c1}{\PYZsh{} left dimension of A}
         \PY{n}{n} \PY{o}{=} \PY{n}{A}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}  \PY{c+c1}{\PYZsh{} right dimension of A}
         
         \PY{c+c1}{\PYZsh{} choose some k singular values we want}
         \PY{n}{k} \PY{o}{=} \PY{l+m+mi}{20}
         
         \PY{c+c1}{\PYZsh{} set parameters}
         \PY{n}{size\PYZus{}gauss} \PY{o}{=} \PY{l+m+mi}{60}
         \PY{n}{pow\PYZus{}iter} \PY{o}{=} \PY{l+m+mi}{50}
         
         \PY{c+c1}{\PYZsh{} initialize the dictionary of values}
         \PY{n}{U}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}\PY{p}{;} \PY{n}{Sigma}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}\PY{p}{;} \PY{n}{V}\PY{o}{=}\PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
\end{Verbatim}


    \hypertarget{numpys-implementation}{%
\subparagraph{Numpy's Implementation}\label{numpys-implementation}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         
         \PY{n}{U}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{svd}\PY{p}{(}\PY{n}{A}\PY{p}{)}
         
         \PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{n}{k}\PY{p}{]}
         \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{T}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{n}{k}\PY{p}{]}
\end{Verbatim}


    \hypertarget{facebook-pcas-implementation}{%
\subparagraph{Facebook PCA's
Implementation}\label{facebook-pcas-implementation}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{c+c1}{\PYZsh{} import fbpca as fbpca}
         
         
         \PY{c+c1}{\PYZsh{} Sigma[\PYZsq{}fbpca\PYZsq{}], V[\PYZsq{}fbpca\PYZsq{}] = fbpca.eigenn(A=A, k=k)}
\end{Verbatim}


    \hypertarget{scikit-learns-implementation}{%
\subparagraph{Scikit-Learn's
Implementation}\label{scikit-learns-implementation}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{utils}\PY{n+nn}{.}\PY{n+nn}{extmath} \PY{k}{import} \PY{n}{randomized\PYZus{}svd}
         \PY{c+c1}{\PYZsh{} randomized SVD}
         \PY{n}{U}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rscikit}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rscikit}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rscikit}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{randomized\PYZus{}svd}\PY{p}{(}\PY{n}{M}\PY{o}{=}\PY{n}{A}\PY{p}{,} \PY{n}{n\PYZus{}components}\PY{o}{=}\PY{n}{k}\PY{p}{,}
                                                                    \PY{n}{n\PYZus{}iter}\PY{o}{=}\PY{n}{pow\PYZus{}iter}\PY{p}{)}
         \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rscikit}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rscikit}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{T}
\end{Verbatim}


    \hypertarget{my-implementation}{%
\subparagraph{My Implementation}\label{my-implementation}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{n}{U}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{asvd}\PY{p}{(}\PY{n}{A}\PY{p}{,} \PY{n}{n\PYZus{}components}\PY{o}{=}\PY{n}{k}\PY{p}{,}
                                                    \PY{n}{size\PYZus{}gauss}\PY{o}{=}\PY{n}{size\PYZus{}gauss}\PY{p}{,}
                                                    \PY{n}{pow\PYZus{}iter}\PY{o}{=}\PY{n}{pow\PYZus{}iter}\PY{p}{)}
\end{Verbatim}


    \hypertarget{scipy-sparse-implementation}{%
\subparagraph{Scipy Sparse
Implementation}\label{scipy-sparse-implementation}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{sparse}\PY{n+nn}{.}\PY{n+nn}{linalg} \PY{k}{import} \PY{n}{svds}
         \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{sparse} \PY{k}{import} \PY{n}{csr\PYZus{}matrix}
         
         \PY{n}{U}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{Sigma}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{svds}\PY{p}{(}\PY{n}{A}\PY{o}{=}\PY{n}{csr\PYZus{}matrix}\PY{p}{(}\PY{n}{A}\PY{p}{)}\PY{p}{,}\PY{n}{k}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,}
                                                       \PY{n}{which}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LM}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                                                       \PY{n}{maxiter}\PY{o}{=}\PY{n}{pow\PYZus{}iter}\PY{p}{)}
         
         \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{V}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{T}
\end{Verbatim}


    \hypertarget{computing-the-spectral-norms}{%
\subsubsection{Computing the Spectral
Norms}\label{computing-the-spectral-norms}}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}37}]:} \PY{c+c1}{\PYZsh{} Copied from FBPCA algorithm}
         \PY{k+kn}{import} \PY{n+nn}{scipy} 
         
         \PY{k}{def} \PY{n+nf}{diffsnorms}\PY{p}{(}\PY{n}{A}\PY{p}{,} \PY{n}{S}\PY{p}{,} \PY{n}{V}\PY{p}{,} \PY{n}{n\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    2\PYZhy{}norm accuracy of a Schur decomp. of a matrix.}
         \PY{l+s+sd}{    Computes an estimate snorm of the spectral norm (the operator norm}
         \PY{l+s+sd}{    induced by the Euclidean vector norm) of A\PYZhy{}VSV\PYZsq{}, using n\PYZus{}iter}
         \PY{l+s+sd}{    iterations of the power method started with a random vector;}
         \PY{l+s+sd}{    n\PYZus{}iter must be a positive integer.}
         \PY{l+s+sd}{    Increasing n\PYZus{}iter improves the accuracy of the estimate snorm of}
         \PY{l+s+sd}{    the spectral norm of A\PYZhy{}VSV\PYZsq{}.}
         \PY{l+s+sd}{    Notes}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    To obtain repeatable results, reset the seed for the pseudorandom}
         \PY{l+s+sd}{    number generator.}
         \PY{l+s+sd}{    Parameters}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    A : array\PYZus{}like}
         \PY{l+s+sd}{        first matrix in A\PYZhy{}VSV\PYZsq{} whose spectral norm is being estimated}
         \PY{l+s+sd}{    S : array\PYZus{}like}
         \PY{l+s+sd}{        third matrix in A\PYZhy{}VSV\PYZsq{} whose spectral norm is being estimated}
         \PY{l+s+sd}{    V : array\PYZus{}like}
         \PY{l+s+sd}{        second matrix in A\PYZhy{}VSV\PYZsq{} whose spectral norm is being estimated}
         \PY{l+s+sd}{    n\PYZus{}iter : int, optional}
         \PY{l+s+sd}{        number of iterations of the power method to conduct;}
         \PY{l+s+sd}{        n\PYZus{}iter must be a positive integer, and defaults to 20}
         \PY{l+s+sd}{    Returns}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    float}
         \PY{l+s+sd}{        an estimate of the spectral norm of A\PYZhy{}VSV\PYZsq{} (the estimate fails}
         \PY{l+s+sd}{        to be accurate with exponentially low probability as n\PYZus{}iter}
         \PY{l+s+sd}{        increases; see references DS1\PYZus{}, DS2\PYZus{}, and DS3\PYZus{} below)}
         \PY{l+s+sd}{    Examples}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} from fbpca import diffsnorms, eigenn}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} from numpy import diag}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} from numpy.random import uniform}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} from scipy.linalg import svd}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{}}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} A = uniform(low=\PYZhy{}1.0, high=1.0, size=(2, 100))}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} A = A.T.dot(A)}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} (U, s, Va) = svd(A, full\PYZus{}matrices=False)}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} A = A / s[0]}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{}}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} (d, V) = eigenn(A, 2)}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} err = diffsnorms(A, diag(d), V)}
         \PY{l+s+sd}{    \PYZgt{}\PYZgt{}\PYZgt{} print(err)}
         \PY{l+s+sd}{    This example produces a rank\PYZhy{}2 approximation V diag(d) V\PYZsq{} to A}
         \PY{l+s+sd}{    such that the columns of V are orthonormal and the entries of d}
         \PY{l+s+sd}{    are nonnegative and are nonincreasing.}
         \PY{l+s+sd}{    diffsnorms(A, diag(d), V) outputs an estimate of the spectral norm}
         \PY{l+s+sd}{    of A \PYZhy{} V diag(d) V\PYZsq{}, which should be close to the machine}
         \PY{l+s+sd}{    precision.}
         \PY{l+s+sd}{    References}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    .. [DS1] Jacek Kuczynski and Henryk Wozniakowski, Estimating the}
         \PY{l+s+sd}{             largest eigenvalues by the power and Lanczos methods with}
         \PY{l+s+sd}{             a random start, SIAM Journal on Matrix Analysis and}
         \PY{l+s+sd}{             Applications, 13 (4): 1094\PYZhy{}1122, 1992.}
         \PY{l+s+sd}{    .. [DS2] Edo Liberty, Franco Woolfe, Per\PYZhy{}Gunnar Martinsson,}
         \PY{l+s+sd}{             Vladimir Rokhlin, and Mark Tygert, Randomized algorithms}
         \PY{l+s+sd}{             for the low\PYZhy{}rank approximation of matrices, Proceedings of}
         \PY{l+s+sd}{             the National Academy of Sciences (USA), 104 (51):}
         \PY{l+s+sd}{             20167\PYZhy{}20172, 2007. (See the appendix.)}
         \PY{l+s+sd}{    .. [DS3] Franco Woolfe, Edo Liberty, Vladimir Rokhlin, and Mark}
         \PY{l+s+sd}{             Tygert, A fast randomized algorithm for the approximation}
         \PY{l+s+sd}{             of matrices, Applied and Computational Harmonic Analysis,}
         \PY{l+s+sd}{             25 (3): 335\PYZhy{}366, 2008. (See Section 3.4.)}
         \PY{l+s+sd}{    See also}
         \PY{l+s+sd}{    \PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}\PYZhy{}}
         \PY{l+s+sd}{    eigenn, eigens}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
         
             \PY{p}{(}\PY{n}{m}\PY{p}{,} \PY{n}{n}\PY{p}{)} \PY{o}{=} \PY{n}{A}\PY{o}{.}\PY{n}{shape}
             \PY{p}{(}\PY{n}{m2}\PY{p}{,} \PY{n}{k}\PY{p}{)} \PY{o}{=} \PY{n}{V}\PY{o}{.}\PY{n}{shape}
             \PY{p}{(}\PY{n}{k2}\PY{p}{,} \PY{n}{k3}\PY{p}{)} \PY{o}{=} \PY{n}{S}\PY{o}{.}\PY{n}{shape}
         
             \PY{k}{assert} \PY{n}{m} \PY{o}{==} \PY{n}{n}
             \PY{k}{assert} \PY{n}{m} \PY{o}{==} \PY{n}{m2}
             \PY{k}{assert} \PY{n}{k} \PY{o}{==} \PY{n}{k2}
             \PY{k}{assert} \PY{n}{k2} \PY{o}{==} \PY{n}{k3}
         
             \PY{k}{assert} \PY{n}{n\PYZus{}iter} \PY{o}{\PYZgt{}}\PY{o}{=} \PY{l+m+mi}{1}
         
             \PY{k}{if} \PY{n}{np}\PY{o}{.}\PY{n}{isrealobj}\PY{p}{(}\PY{n}{A}\PY{p}{)} \PY{o+ow}{and} \PY{n}{np}\PY{o}{.}\PY{n}{isrealobj}\PY{p}{(}\PY{n}{V}\PY{p}{)} \PY{o+ow}{and} \PY{n}{np}\PY{o}{.}\PY{n}{isrealobj}\PY{p}{(}\PY{n}{S}\PY{p}{)}\PY{p}{:}
                 \PY{n}{isreal} \PY{o}{=} \PY{k+kc}{True}
             \PY{k}{else}\PY{p}{:}
                 \PY{n}{isreal} \PY{o}{=} \PY{k+kc}{False}
         
             \PY{c+c1}{\PYZsh{} Promote the types of integer data to float data.}
             \PY{n}{dtype} \PY{o}{=} \PY{p}{(}\PY{n}{A} \PY{o}{*} \PY{l+m+mf}{1.0}\PY{p}{)}\PY{o}{.}\PY{n}{dtype}
         
             \PY{c+c1}{\PYZsh{}}
             \PY{c+c1}{\PYZsh{} Generate a random vector x.}
             \PY{c+c1}{\PYZsh{}}
             \PY{k}{if} \PY{n}{isreal}\PY{p}{:}
                 \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{n}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{dtype}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                 \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{n}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{dtype}\PY{p}{)} \PYZbs{}
                     \PY{o}{+} \PY{l+m+mi}{1}\PY{n}{j} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{size}\PY{o}{=}\PY{p}{(}\PY{n}{n}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n}{dtype}\PY{p}{)}
         
             \PY{n}{x} \PY{o}{=} \PY{n}{x} \PY{o}{/} \PY{n}{scipy}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n}{x}\PY{p}{)}
         
             \PY{c+c1}{\PYZsh{}}
             \PY{c+c1}{\PYZsh{} Run n\PYZus{}iter iterations of the power method.}
             \PY{c+c1}{\PYZsh{}}
             \PY{k}{for} \PY{n}{it} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{n\PYZus{}iter}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{}}
                 \PY{c+c1}{\PYZsh{} Set y = (A\PYZhy{}VSV\PYZsq{})x.}
                 \PY{c+c1}{\PYZsh{}}
                 \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{A}\PY{p}{,} \PY{n}{x}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{V}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{S}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{V}\PY{o}{.}\PY{n}{conj}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{T}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}}
                 \PY{c+c1}{\PYZsh{} Set x = (A\PYZsq{}\PYZhy{}VS\PYZsq{}V\PYZsq{})y.}
                 \PY{c+c1}{\PYZsh{}}
                 \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{y}\PY{o}{.}\PY{n}{conj}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n}{A}\PY{p}{)}\PY{o}{.}\PY{n}{conj}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{T} \PYZbs{}
                     \PY{o}{\PYZhy{}} \PY{n}{V}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{S}\PY{o}{.}\PY{n}{conj}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{T}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{V}\PY{o}{.}\PY{n}{conj}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{T}\PY{o}{.}\PY{n}{dot}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         
                 \PY{c+c1}{\PYZsh{}}
                 \PY{c+c1}{\PYZsh{} Normalize x, memorizing its Euclidean norm.}
                 \PY{c+c1}{\PYZsh{}}
                 \PY{n}{snorm} \PY{o}{=} \PY{n}{scipy}\PY{o}{.}\PY{n}{linalg}\PY{o}{.}\PY{n}{norm}\PY{p}{(}\PY{n}{x}\PY{p}{)}
                 \PY{k}{if} \PY{n}{snorm} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{:}
                     \PY{k}{return} \PY{l+m+mi}{0}
                 \PY{n}{x} \PY{o}{=} \PY{n}{x} \PY{o}{/} \PY{n}{snorm}
         
             \PY{n}{snorm} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{snorm}\PY{p}{)}
         
             \PY{k}{return} \PY{n}{snorm}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{c+c1}{\PYZsh{} compute the norm for the difference between implementations}
         \PY{n}{norm} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         
         \PY{n}{methods} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rscikit}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{asvd}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{np}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{scipy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         
         \PY{k}{for} \PY{n}{method} \PY{o+ow}{in} \PY{n}{methods}\PY{p}{:}
         \PY{c+c1}{\PYZsh{}     S = Sigma[method]}
         \PY{c+c1}{\PYZsh{}     v = V[method]}
         \PY{c+c1}{\PYZsh{}     print(S, v)}
             \PY{n}{norm}\PY{p}{[}\PY{n}{method}\PY{p}{]} \PY{o}{=} \PY{n}{diffsnorms}\PY{p}{(}\PY{n}{A}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{diag}\PY{p}{(}\PY{n}{Sigma}\PY{p}{[}\PY{n}{method}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{V}\PY{p}{[}\PY{n}{method}\PY{p}{]}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Norm for }\PY{l+s+si}{\PYZob{}m\PYZcb{}}\PY{l+s+s1}{ method: }\PY{l+s+si}{\PYZob{}n\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{m}\PY{o}{=}\PY{n}{method}\PY{p}{,}\PY{n}{n}\PY{o}{=}\PY{n}{norm}\PY{p}{[}\PY{n}{method}\PY{p}{]}\PY{p}{)}\PY{p}{)}
             
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Norm for rscikit method: 0.8382706081688264
Norm for asvd method: 0.9455247687394075
Norm for np method: 0.8289495843285444
Norm for scipy method: 0.8204619047434387

    \end{Verbatim}

    I'll be honest, I have no idea what's a good or bad spectral norm value.
Typically the lower the number the better. But both numbers are so close
to 1 so maybe the higher the number the better? Who knows..


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
